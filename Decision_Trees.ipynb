{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5c1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eddab5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.data = None\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.train_X = None\n",
    "        self.train_Y = None\n",
    "        self.test_X = None\n",
    "        self.test_Y = None\n",
    "        self.ID3accuracy = []\n",
    "        self.CARTaccuracy = []\n",
    "        self.C45accuracy = []\n",
    "        self.gb_accuracy = []\n",
    "        self.rf_accuracy = []\n",
    "\n",
    "    def data_preprocessing(self):\n",
    "        self.data = pd.read_csv(self.url)\n",
    "        self.data.dropna(inplace=True)\n",
    "        self.data.drop_duplicates(inplace=True)\n",
    "        self.data.fillna(self.data.mean(), inplace=True)\n",
    "\n",
    "    def corr(self):\n",
    "        corr = self.data.corr()\n",
    "        self.data = self.data.drop(['Cluster_ID', 'gamemode', 'gametype'], axis=1)\n",
    "\n",
    "    def X_Y_division(self):\n",
    "        self.train_X, self.test_X, self.train_Y, self.test_Y = train_test_split(self.data.iloc[:, :-1],\n",
    "                                                                                self.data.iloc[:, -1],\n",
    "                                                                                test_size=0.2, random_state=43)\n",
    "\n",
    "    def ID3(self):\n",
    "        ID3classifier = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "        ID3classifier.fit(self.train_X, self.train_Y)\n",
    "        y_pred_ID3classifier = ID3classifier.predict(self.test_X)\n",
    "\n",
    "        ID3accuracy = accuracy_score(self.test_Y, y_pred_ID3classifier)\n",
    "        self.ID3accuracy.append(ID3accuracy)\n",
    "        print(\"ID3 classifier: \", ID3accuracy)\n",
    "\n",
    "    def CART(self):\n",
    "        CARTclassifier = DecisionTreeClassifier(criterion=\"gini\")\n",
    "        CARTclassifier.fit(self.train_X, self.train_Y)\n",
    "        y_pred_CARTclassifier = CARTclassifier.predict(self.test_X)\n",
    "\n",
    "        CARTaccuracy = accuracy_score(self.test_Y, y_pred_CARTclassifier)\n",
    "        self.CARTaccuracy.append(CARTaccuracy)\n",
    "        print(\"CART classifier: \", CARTaccuracy)\n",
    "\n",
    "    def C45(self):\n",
    "        C45classifier = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\")\n",
    "        C45classifier.fit(self.train_X, self.train_Y)\n",
    "        y_pred_C45classifier = C45classifier.predict(self.test_X)\n",
    "\n",
    "        C45accuracy = accuracy_score(self.test_Y, y_pred_C45classifier)\n",
    "        self.C45accuracy.append(C45accuracy)\n",
    "        print(\"C4.5 classifier: \", C45accuracy)\n",
    "        \n",
    "    def entropy(dataset):\n",
    "        classes = {}\n",
    "        total = len(dataset)\n",
    "\n",
    "        # Count the occurrences of each class label\n",
    "        for data in dataset:\n",
    "            label = data[-1]\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "\n",
    "        entropy_value = 0.0\n",
    "\n",
    "        # Calculate the entropy\n",
    "        for count in classes.values():\n",
    "            probability = count / total\n",
    "            entropy_value -= probability * math.log2(probability)\n",
    "\n",
    "        return entropy_value\n",
    "\n",
    "    def information_gain(dataset, attribute_index):\n",
    "        attribute_values = {}\n",
    "        total = len(dataset)\n",
    "\n",
    "        for data in dataset:\n",
    "            attribute_value = data[attribute_index]\n",
    "            if attribute_value not in attribute_values:\n",
    "                attribute_values[attribute_value] = []\n",
    "            attribute_values[attribute_value].append(data)\n",
    "\n",
    "        gain = entropy(dataset)\n",
    "        for attribute_data in attribute_values.values():\n",
    "            proportion = len(attribute_data) / total\n",
    "            gain -= proportion * entropy(attribute_data)\n",
    "\n",
    "        return gain\n",
    "    \n",
    "    def calculate_entropy(data):\n",
    "    class_counts = {}\n",
    "    total_data = len(data)\n",
    "\n",
    "    # Count the occurrences of each class label\n",
    "    for row in data:\n",
    "        label = row[-1]\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    entropy = 0.0\n",
    "    for count in class_counts.values():\n",
    "        probability = count / total_data\n",
    "        entropy -= probability * math.log2(probability)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "    def calculate_attribute_entropy(data, attribute_index):\n",
    "        attribute_values = {}\n",
    "        total_data = len(data)\n",
    "\n",
    "        # Count the occurrences of each attribute value\n",
    "        for row in data:\n",
    "            attribute_value = row[attribute_index]\n",
    "            if attribute_value not in attribute_values:\n",
    "                attribute_values[attribute_value] = 0\n",
    "            attribute_values[attribute_value] += 1\n",
    "\n",
    "        attribute_entropy = 0.0\n",
    "        for count in attribute_values.values():\n",
    "            probability = count / total_data\n",
    "            attribute_entropy -= probability * math.log2(probability)\n",
    "\n",
    "        return attribute_entropy\n",
    "    def calculate_gini_index(data):\n",
    "    class_counts = {}\n",
    "    total_data = len(data)\n",
    "\n",
    "    # Count the occurrences of each class label\n",
    "    for row in data:\n",
    "        label = row[-1]\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "\n",
    "    gini_index = 1.0\n",
    "    for count in class_counts.values():\n",
    "        probability = count / total_data\n",
    "        gini_index -= probability ** 2\n",
    "\n",
    "    return gini_index\n",
    "\n",
    "    def calculate_attribute_gini_index(data, attribute_index):\n",
    "        attribute_values = {}\n",
    "        total_data = len(data)\n",
    "\n",
    "        # Count the occurrences of each attribute value\n",
    "        for row in data:\n",
    "            attribute_value = row[attribute_index]\n",
    "            if attribute_value not in attribute_values:\n",
    "                attribute_values[attribute_value] = 0\n",
    "            attribute_values[attribute_value] += 1\n",
    "\n",
    "        attribute_gini_index = 0.0\n",
    "        for count in attribute_values.values():\n",
    "            probability = count / total_data\n",
    "            attribute_gini_index += probability ** 2\n",
    "\n",
    "        return 1 - attribute_gini_index\n",
    "\n",
    "    def calculate_gini_gain(data, attribute_index):\n",
    "        gini_index = calculate_gini_index(data)\n",
    "        attribute_gini_index = calculate_attribute_gini_index(data, attribute_index)\n",
    "\n",
    "        gini_gain = gini_index - attribute_gini_index\n",
    "\n",
    "        return gini_gain\n",
    "\n",
    "        def calculate_split_information(data, attribute_index):\n",
    "            attribute_values = {}\n",
    "            total_data = len(data)\n",
    "\n",
    "            # Count the occurrences of each attribute value\n",
    "            for row in data:\n",
    "                attribute_value = row[attribute_index]\n",
    "                if attribute_value not in attribute_values:\n",
    "                    attribute_values[attribute_value] = 0\n",
    "                attribute_values[attribute_value] += 1\n",
    "\n",
    "            split_information = 0.0\n",
    "            for count in attribute_values.values():\n",
    "                probability = count / total_data\n",
    "                split_information -= probability * math.log2(probability)\n",
    "\n",
    "            return split_information\n",
    "\n",
    "    def calculate_information_gain_ratio(data, attribute_index):\n",
    "        entropy = calculate_entropy(data)\n",
    "        attribute_entropy = calculate_attribute_entropy(data, attribute_index)\n",
    "        split_information = calculate_split_information(data, attribute_index)\n",
    "\n",
    "        information_gain = entropy - attribute_entropy\n",
    "        information_gain_ratio = information_gain / split_information\n",
    "\n",
    "        return information_gain_ratio\n",
    "    \n",
    "\n",
    "    def gradientBoosting(self):\n",
    "        gb_classifier = GradientBoostingClassifier()\n",
    "        gb_classifier.fit(self.train_X, self.train_Y)\n",
    "        gb_y_pred = gb_classifier.predict(self.test_X)\n",
    "        gb_accuracy = accuracy_score(self.test_Y, gb_y_pred)\n",
    "        self.gb_accuracy.append(gb_accuracy)\n",
    "        print(\"Gradient Boosting Accuracy:\", gb_accuracy)\n",
    "\n",
    "    def RandomForest(self):\n",
    "        rf_classifier = RandomForestClassifier()\n",
    "        rf_classifier.fit(self.train_X, self.train_Y)\n",
    "        rf_y_pred = rf_classifier.predict(self.test_X)\n",
    "        rf_accuracy = accuracy_score(self.test_Y, rf_y_pred)\n",
    "        self.rf_accuracy.append(rf_accuracy)\n",
    "        print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "    def visualize_results(self):\n",
    "        classifiers = [\"ID3\", \"CART\", \"C4.5\", \"Gradient Boosting\", \"Random Forest\"]\n",
    "        accuracies = [self.ID3accuracy, self.CARTaccuracy, self.C45accuracy, self.gb_accuracy, self.rf_accuracy]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        for i in range(len(classifiers)):\n",
    "            ax.plot(range(1, len(accuracies[i]) + 1), accuracies[i], label=classifiers[i])\n",
    "\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.set_title('Algorithm Accuracies')\n",
    "        ax.legend()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "536ee808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74120, 112)\n",
      "(74120,)\n",
      "(18530, 112)\n",
      "(18530,)\n",
      "ID3 classifier:  0.9235833783054507\n",
      "CART classifier:  0.921856449001619\n",
      "C4.5 classifier:  0.923907177549919\n",
      "Gradient Boosting Accuracy: 0.95876956287102\n",
      "Random Forest Accuracy: 0.9592012951969778\n"
     ]
    }
   ],
   "source": [
    "dt = decisionTree('https://raw.githubusercontent.com/YaswanthAdari/Gradient_descent_/main/dota2.csv')\n",
    "dt.data_preprocessing()\n",
    "dt.X_Y_division()\n",
    "train_X, test_X, train_Y, test_Y = dt.train_test_split()\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "dt.ID3()\n",
    "dt.CART()\n",
    "dt.C45()\n",
    "dt.gradientBoosting()\n",
    "dt.RandomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9402b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
